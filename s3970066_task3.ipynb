{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Data Parsing, Cleansing and Integration\n",
    "## Task 3\n",
    "#### Student Name: XXXX XXXX\n",
    "#### Student ID: 000000\n",
    "\n",
    "Date: XXXX\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include the main libraries you used in your assignment, e.g.,:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "\n",
    "\n",
    "## Introduction\n",
    "Give general information of this assessment here, e.g., what problems you encounter in integration, general steps and solutions you've taken to integrate the data. \n",
    "\n",
    "<span style=\"color: red\"> Note that this is a sample notebook only. You will need to fill in the proper markdown and code blocks. You might also want to make necessary changes to the structure to meet your own needs. Note also that any generic comments written in this notebook are to be removed and replace with your own words.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries needed\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Examining and loading data\n",
    "Examine \"\\<student\\_id\\>_dataset2.csv\" the structure and schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to inspect the provided data file\n",
    "# Couple of notes for all code block in this notebook\n",
    "## please provide proper comment on your code\n",
    "## Please re-start and run all cells to make sure codes are runable and include your output in the submission\n",
    "\n",
    "# Reading the two datasets\n",
    "df1 = pd.read_csv('s3970066_dataset1_solution.csv')\n",
    "df2 = pd.read_csv('s3970066_dataset2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Resolving schema conflicts\n",
    "Give some general information about the conflicts you found in two schemas and steps you taken to resolve them.\n",
    "\n",
    "<span style=\"color: red\"> You might have complex notebook structure in this section, please feel free to create your own notebook structure. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conflict 1: XXXX (e.g. naming conflicts in xx column and xx column)\n",
    "Here give some general information about this conflict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Code to inspect data and identify conflicts in schema\n",
    "# Createing a function to generate unique IDs for df2\n",
    "def generate_unique_ids(start, n):\n",
    "    return list(range(start, start + n))\n",
    "\n",
    "# renaming and mapping the columns of df2 to match df1\n",
    "df2 = df2.rename(columns={\n",
    "    'Monthly Payment': 'AnnualSalary',\n",
    "    'Closing': 'CloseDate',\n",
    "    'Organisation': 'Company',\n",
    "    'Opening': 'OpenDate',\n",
    "    'Job Title': 'Title',\n",
    "    'Type': 'ContractType',\n",
    "    'Full-Time Equivalent (FTE)': 'ContractTime'\n",
    "})\n",
    "\n",
    "# converting Monthly Payment to annual in df2\n",
    "df2['AnnualSalary'] = df2['AnnualSalary'] * 12\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell me about how you fix the conflict here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to fix the conflict\n",
    "# converting 'Full-Time Equivalent (FTE)' to 'contract' or 'permanent'\n",
    "def contract_time_converter(x):\n",
    "    if isinstance(x, (int, float)):\n",
    "        return 'contract' if x < 1 else 'permanent'\n",
    "    else:\n",
    "        # handling unexpected string values, \n",
    "        return 'unknown'  # raising an error, or converting known strings to appropriate values\n",
    "\n",
    "df2['ContractTime'] = df2['ContractTime'].apply(contract_time_converter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conflict 2: XXXX\n",
    "......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merging data\n",
    "\n",
    "<span style=\"color: red\"> You might have complex notebook structure in this section, please feel free to create your own notebook structure. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to merge two data sets\n",
    "\n",
    "# generating the unique Ids for df2\n",
    "max_id_df1 = df1['Id'].max()\n",
    "df2['Id'] = generate_unique_ids(max_id_df1 + 1, len(df2))\n",
    "\n",
    "# setting a uniform source name for the second dataset\n",
    "df2['SourceName'] = 'www.jobhuntlisting.com'\n",
    "\n",
    "# checking and adding missing columns in df2\n",
    "for column in df1.columns:\n",
    "    if column not in df2.columns:\n",
    "        df2[column] = None  # this sets the entire column to NaN for missing columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Resolving data conflicts:\n",
    "Give some general information about the data conflicts you found in the unified table and how you resolve them.\n",
    "\n",
    "<span style=\"color: red\"> You might have complex notebook structure in this section, please feel free to create your own notebook structure. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conflict 1: XXXX (e.g., complete duplications)\n",
    "Here give some general information about this conflict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to inspect data and identify conflicts in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell me about how you fix the conflict here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to fix the conflict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding global key for the data\n",
    "Find a proper global key for the integrated data and give justification here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to identify global key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conflict 2: XXXX (e.g., other duplications)\n",
    "Here give some general information about this conflict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Saving the integrated and reshaped data\n",
    "The last part of the integration process is to export our output data to csv format, named as:\n",
    "- '\\<student\\_id\\>_dataset_integrated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data integration complete! Unified dataset saved as s3970066_dataset_integrated.csv.\n"
     ]
    }
   ],
   "source": [
    "# code to save output data\n",
    "# selecting only the columns that are present in df1 to have a unified structure\n",
    "df2 = df2[df1.columns]\n",
    "\n",
    "# concatenating the two dataframes\n",
    "result_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# saving the result to a CSV\n",
    "result_df.to_csv('s3970066_dataset_integrated.csv', index=False)\n",
    "\n",
    "print(\"Data integration complete! Unified dataset saved as s3970066_dataset_integrated.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the Assessment Task\n",
    "Give a short summary and anything you would like to talk about this assessment task here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
